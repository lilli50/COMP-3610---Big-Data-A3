{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1685a507-389a-48d4-91aa-040fbc7bf5e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install pyspark --default-timeout=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e71b80-e751-411e-81c4-eb17a1bd792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9c2709-11f9-4332-ab54-4ef7cd6adaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Code to set JAVA HOME and Create Environment for Spark Session\n",
    "os.environ[\"JAVA_HOME\"] = \"C:/Users/student/Desktop/Lillian Charles/Y3 S2/COMP 3610 - Big Data/Assignments/Java/jdk8u452-b09\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"\\\\bin;\" + os.environ[\"PATH\"]\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bebee14c-0f26-4e98-8ceb-0621e0f23af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME: C:/Users/student/Desktop/Lillian Charles/Y3 S2/COMP 3610 - Big Data/Assignments/Java/jdk8u452-b09\n",
      "openjdk version \"1.8.0_452\"\n",
      "OpenJDK Runtime Environment (Temurin)(build 1.8.0_452-b09)\n",
      "OpenJDK 64-Bit Server VM (Temurin)(build 25.452-b09, mixed mode)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Code to Check Java Setup\n",
    "print(\"JAVA_HOME:\", os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([\"java\", \"-version\"], capture_output=True, text=True)\n",
    "    print(result.stderr)\n",
    "except Exception as e:\n",
    "    print(\"Error running java:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f9a44-4ebb-4060-ada2-f6e0c4c19c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Spark Session\n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder.appName(\"Amazon Review Project\").config(\"spark.driver.memory\", \"12g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adcd1a7-6ebf-47cc-a3aa-feeb1a093299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from pyspark.sql.functions import col, udf, size, split, to_timestamp, year\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be50fb4-e686-4c6c-8e72-d5dbdf9d6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert rows in the data to String. Prevents inference errors\n",
    "import json\n",
    "\n",
    "def stringify_fields(rows, fields):\n",
    "    for row in rows:\n",
    "        for field in fields:\n",
    "            if field in row and row[field] is not None:\n",
    "                try:\n",
    "                    row[field] = json.dumps(row[field])\n",
    "                except:\n",
    "                    row[field] = str(row[field])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5edbecb-2d10-4ebb-a217-954f621e336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove empyt columns from the dataset\n",
    "def remove_empty_columns(rows):\n",
    "    if not rows:\n",
    "        return rows\n",
    "    keys = list(rows[0].keys())\n",
    "    for key in keys:\n",
    "        if all(row.get(key) is None for row in rows):\n",
    "            for row in rows:\n",
    "                row.pop(key, None)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121da495-1371-4926-9563-6b6655643e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#Function to automatically set the schema for the datasets.\n",
    "def infer_spark_schema(sample_row):\n",
    "    type_mapping = {\n",
    "        str: StringType(),\n",
    "        int: IntegerType(),\n",
    "        float: FloatType(),\n",
    "        bool: BooleanType(),\n",
    "        type(None): StringType()  # Treat None as StringType\n",
    "    }\n",
    "\n",
    "    fields = []\n",
    "    for key, value in sample_row.items():\n",
    "        if isinstance(value, (dict, list)):\n",
    "            fields.append(StructField(key, StringType(), True))  # stringify complex stuff\n",
    "        else:\n",
    "            spark_type = type_mapping.get(type(value), StringType())\n",
    "            fields.append(StructField(key, spark_type, True))\n",
    "    \n",
    "    return StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94cba655-8277-40b7-b16c-849924127824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the categories into the program and execute data cleaning\n",
    "def load_and_process_categories(base_path, category):\n",
    "\n",
    "    print(f\"⚙️ Loading category {category}...\")\n",
    "    \n",
    "    review_path = os.path.join(base_path, f\"raw_review_{category}\")\n",
    "    meta_path = os.path.join(base_path, f\"raw_meta_{category}\")\n",
    "\n",
    "    review_data = load_from_disk(review_path)[\"full\"]\n",
    "    meta_data = load_from_disk(meta_path)[\"full\"]\n",
    "    \n",
    "    review_rows = review_data.to_list()\n",
    "    meta_rows = meta_data.to_list()\n",
    "\n",
    "   # Auto schema: meta\n",
    "    meta_schema = infer_spark_schema(meta_rows[0])\n",
    "\n",
    "    # Stringify problematic fields\n",
    "    problem_fields = [\"images\", \"features\", \"description\", \"specs\", \"feature_vectors\"]\n",
    "    review_rows = stringify_fields(review_rows, problem_fields)\n",
    "    meta_rows = stringify_fields(meta_rows, problem_fields)\n",
    "\n",
    "    review_rows = remove_empty_columns(review_rows)\n",
    "    meta_rows = remove_empty_columns(meta_rows)\n",
    "\n",
    "    # Create Spark DataFrames safely\n",
    "    try:\n",
    "        review_schema = infer_spark_schema(review_rows[0])\n",
    "        review_df = spark.createDataFrame(review_rows, schema=review_schema)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not infer schema for review in {category}: {e}. Using Spark's automatic inference.\")\n",
    "        review_df = spark.createDataFrame(review_rows)\n",
    "    \n",
    "    meta_df = spark.createDataFrame(meta_rows, schema=meta_schema)\n",
    "\n",
    "\n",
    "    for col_name in [\"images\", \"title\"]:\n",
    "        if col_name in meta_df.columns:\n",
    "            meta_df = meta_df.withColumnRenamed(col_name, f\"{col_name}_meta\")\n",
    "        \n",
    "    # Merge on parent_asin\n",
    "    merged_df = review_df.join(meta_df, on=\"parent_asin\", how=\"left\")\n",
    "\n",
    "    #Drop rows where rating is missing or not in [1–5], drop rows if text (the review body) is empty or null\n",
    "    merged_df = merged_df.filter((col(\"rating\").between(1, 5) & (col(\"Text\").isNotNull()) & (col(\"text\") != \"\")))\n",
    "\n",
    "    def get_brand(details, store):\n",
    "        if isinstance(details, dict) and \"brand\" in details:\n",
    "            return details[\"brand\"]\n",
    "        return store if store else \"Unknown\"\n",
    "\n",
    "    brand_udf = udf(get_brand, StringType())\n",
    "    merged_df = merged_df.withColumn(\"brand\", brand_udf(col(\"details\"), col(\"store\")))\n",
    "\n",
    "    # Remove duplicates\n",
    "    merged_df = merged_df.dropDuplicates([\"user_id\", \"asin\", \"text\"])\n",
    "\n",
    "    # Derived columns\n",
    "    merged_df = merged_df.withColumn(\"review_length\",size(split(col(\"text\"), \"\")))\n",
    "    merged_df = merged_df.withColumn(\"timestamp\", to_timestamp((col(\"timestamp\")/1000).cast(\"long\")))\n",
    "    merged_df = merged_df.withColumn(\"year\", year(col(\"timestamp\")))\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ccd6e4-ee19-4802-b9c0-fbbb2928fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdata_a3_utils import VALID_CATEGORIES\n",
    "\n",
    "# Path where files are stored\n",
    "base_path = \"./review_files\"\n",
    "all_dfs = [] # array to hold the processed and loaded categories\n",
    "\n",
    "# Code to split the categories into 5 batches for processing\n",
    "batch_size = 5\n",
    "category_batches = [VALID_CATEGORIES[i:i + batch_size] for i in range(0, len(VALID_CATEGORIES), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff571e2b-a61a-47f0-a73e-795bfedf9a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Loading category All_Beauty...\n",
      "⚠️ Could not infer schema for review in All_Beauty: [VALUE_OUT_OF_BOUND] Value for `obj` must be greater than 2147483647 or less than -2147483648, got 1588687728923. Using Spark's automatic inference.\n",
      "✅ All_Beauty addedd to all_dfs\n",
      "⚙️ Loading category Amazon_Fashion...\n",
      "⚠️ Could not infer schema for review in Amazon_Fashion: [VALUE_OUT_OF_BOUND] Value for `obj` must be greater than 2147483647 or less than -2147483648, got 1578528394489. Using Spark's automatic inference.\n",
      "✅ Amazon_Fashion addedd to all_dfs\n",
      "⚙️ Loading category Appliances...\n",
      "⚠️ Could not infer schema for review in Appliances: [VALUE_OUT_OF_BOUND] Value for `obj` must be greater than 2147483647 or less than -2147483648, got 1519317108692. Using Spark's automatic inference.\n",
      "✅ Appliances addedd to all_dfs\n",
      "⚙️ Loading category Arts_Crafts_and_Sewing...\n",
      "⚠️ Could not infer schema for review in Arts_Crafts_and_Sewing: [VALUE_OUT_OF_BOUND] Value for `obj` must be greater than 2147483647 or less than -2147483648, got 1661111719157. Using Spark's automatic inference.\n",
      "✅ Arts_Crafts_and_Sewing addedd to all_dfs\n",
      "⚙️ Loading category Automotive...\n",
      "❌ Failed on Automotive: \n"
     ]
    }
   ],
   "source": [
    "# Categories already processed\n",
    "processed_categories = set([cat for cat, _ in all_dfs])\n",
    "\n",
    "# loop to process categories\n",
    "for category in category_batches:\n",
    "        \n",
    "    if category in processed_categories:\n",
    "        print(f\"⏭️ Skipping {category}, already processed.\")\n",
    "        continue\n",
    "            \n",
    "    try:\n",
    "        df = load_and_process_categories(base_path, category)\n",
    "    \n",
    "        all_dfs.append((category, df))\n",
    "    \n",
    "        print(f\"✅ {category} addedd to all_dfs\")\n",
    "    \n",
    "        del df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed on {category}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bff6d6-96b3-48cb-84a5-f3b60806b2b8",
   "metadata": {},
   "source": [
    "# Unified Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f9fc60d-9217-4772-a143-56bd79b2109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the DataFrames from the (category, df) tuples\n",
    "dfs_only = [df for _, df in all_dfs]\n",
    "\n",
    "# Start with the first DataFrame\n",
    "merged_df = dfs_only[0]\n",
    "\n",
    "# Union the rest of them\n",
    "for df in dfs_only[1:]:\n",
    "    merged_df = merged_df.unionByName(df, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6640737e-1146-477b-a6bd-0e90b81e0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful_vote: long (nullable = true)\n",
      " |-- images: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- verified_purchase: boolean (nullable = true)\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- title_meta: string (nullable = true)\n",
      " |-- average_rating: float (nullable = true)\n",
      " |-- rating_number: integer (nullable = true)\n",
      " |-- features: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- images_meta: string (nullable = true)\n",
      " |-- videos: string (nullable = true)\n",
      " |-- store: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- details: string (nullable = true)\n",
      " |-- bought_together: string (nullable = true)\n",
      " |-- subtitle: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- review_length: integer (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da51211-bcd9-450e-82ab-5ccd3751b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067c88b-3852-43f5-9547-bb7ffdf21447",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d01b4a1-2423-46d8-b2a8-0944d5d352c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5c1ab-b0e4-4101-948f-6f7cdeb46eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Star Rating Histogram\n",
    "filtered_ratings = merged_df.filter((col(\"rating\") >= 1) & (col(\"rating\") <= 5))\n",
    "\n",
    "rating_counts = filtered_ratings.groupBy(\"rating\").count().orderBy(\"rating\")\n",
    "\n",
    "rating_counts_pd = rating_counts.limit(10).toPandas()\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(rating_counts_pd['rating'], rating_counts_pd['count'], color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Star Ratings (1-5)', fontsize=14)\n",
    "plt.xlabel('Rating', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(range(1, 6))  # Set x-ticks to be the star ratings 1-5\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe433f9-3604-4bf2-aed5-262429c4d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart showing top 10 categories\n",
    "category_counts = merged_df.groupBy(\"category\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "top_10_categories = category_counts.limit(10)\n",
    "\n",
    "top_10_categories_pd = top_10_categories.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_10_categories_pd['category'], top_10_categories_pd['count'], color='orange', edgecolor='black')\n",
    "plt.title('Top 10 Categories by Total Review Count', fontsize=14)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Total Review Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate category names for better readability\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0192c-3b1c-4e11-b0fd-3a40b54c8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart showing top 10 brands (excluding \"Unknown\")\n",
    "filtered_df = merged_df.filter(merged_df[\"brand\"] != \"Unknown\")\n",
    "\n",
    "brand_counts = filtered_df.groupBy(\"brand\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "top_10_brands = brand_counts.limit(10)\n",
    "\n",
    "top_10_brands_pd = top_10_brands.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_10_brands_pd['brand'], top_10_brands_pd['count'], color='blue', edgecolor='black')\n",
    "plt.title('Top 10 Brands by Total Review Count (Excluding \"Unknown\")', fontsize=14)\n",
    "plt.xlabel('Brand', fontsize=12)\n",
    "plt.ylabel('Total Review Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate brand names for better readability\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d717ff0-1be9-4d11-b13b-459951db967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line chart of average star rating per year\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "time_based_trend = (\n",
    "    merged_df\n",
    "    .filter(col(\"rating\").isNotNull())  # Filter out null ratings\n",
    "    .groupBy(\"year\")\n",
    "    .agg(F.avg(\"rating\").alias(\"avg_rating\"))\n",
    "    .orderBy(\"year\")\n",
    ")\n",
    "\n",
    "time_based_trend_pd = time_based_trend.toPandas()\n",
    "\n",
    "# Step 3: Plot the time-based trend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_based_trend_pd['year'], time_based_trend_pd['avg_rating'], marker='o', color='b', linestyle='-', linewidth=2, markersize=6)\n",
    "plt.title('Average Star Rating Per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Star Rating')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9b18f-f639-4730-af40-f182aa82af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Pearson correlation\n",
    "from pyspark.sql.functions import length, col\n",
    "\n",
    "merged_df_with_length = merged_df.withColumn('review_length', length(col('text')))\n",
    "\n",
    "correlation = merged_df_with_length.stat.corr('review_length', 'rating')\n",
    "\n",
    "print(f\"Pearson Correlation between review length and star rating: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e9a32-f9ff-41a5-b0ad-0ce8e2a89352",
   "metadata": {},
   "source": [
    "# Binary Sentiment Prediction (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e41b1b68-7256-4bb0-ada3-5bed165690e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Create binary sentiment label: 1 = positive, 0 = negative\n",
    "binary_df = df.withColumn(\n",
    "    \"label\",\n",
    "    when(col(\"rating\") >= 4, 1).otherwise(0)\n",
    ").select(\"label\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f88c58b-c997-4c75-b6ab-6a39ab90505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tf = HashingTF(inputCol=\"filtered\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba0589d8-dc4b-4e59-bff7-a7cd6e238416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad1238de-4f12-4262-a476-f9d3a8df2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, remover, tf, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f358c4-b7fa-4e60-add3-36b740f0ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = binary_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "model = pipeline.fit(train_data)\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08387acf-da47-4464-8848-21a88bf99b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"✅ AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b08b79-e4d0-4d65-a7a1-3049b586620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69fd71-5152-4046-a544-01d41b249f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df = predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
    "confusion_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f7189-8db5-4196-bc91-d466a6cf1ef4",
   "metadata": {},
   "source": [
    "# Recommender System (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1216f21-360d-410e-90d5-498b0f85727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23687344-8162-4ec2-9e7d-c753536db8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = df.select(\"user_id\", \"asin\", \"rating\") \\\n",
    "    .dropna() \\\n",
    "    .withColumn(\"user_id\", df[\"user_id\"].cast(\"string\")) \\\n",
    "    .withColumn(\"asin\", df[\"asin\"].cast(\"string\")) \\\n",
    "    .withColumn(\"rating\", df[\"rating\"].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403234e6-5bb5-40fd-aac6-08541161bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string IDs to numeric\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\").fit(ratings_df)\n",
    "item_indexer = StringIndexer(inputCol=\"asin\", outputCol=\"item_index\").fit(ratings_df)\n",
    "\n",
    "indexed = user_indexer.transform(ratings_df)\n",
    "indexed = item_indexer.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d259dfd-dac6-49e1-ab64-144e3e9b5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS model\n",
    "als = ALS(\n",
    "    userCol=\"user_index\",\n",
    "    itemCol=\"item_index\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",  # drops rows with NaN predictions\n",
    "    implicitPrefs=False\n",
    ")\n",
    "\n",
    "model = als.fit(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb697aec-cdde-4a93-a69e-44b981d753a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "predictions = model.transform(indexed)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82357ff2-ff31-4575-921b-977d241d9771",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ceea46-23e7-440e-a7f5-83cfdd4c1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "user_features = df.groupBy(\"user_id\").agg(\n",
    "    count(\"asin\").alias(\"review_count\"),\n",
    "    avg(\"rating\").alias(\"avg_rating\"),\n",
    "    avg(\"review_length\").alias(\"avg_review_length\")\n",
    ").dropna()\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"review_count\", \"avg_rating\", \"avg_review_length\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "feature_df = assembler.transform(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de579a7-a573-4793-80aa-6ed6a7ec1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=4, seed=42)\n",
    "model = kmeans.fit(feature_df)\n",
    "\n",
    "clusters = model.transform(feature_df)\n",
    "clusters.select(\"user_id\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910579e2-d127-45b7-a561-4da5de2d4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "product_stats = merged_df.groupBy(\"asin\").agg(\n",
    "    avg(\"rating\").alias(\"mean_rating\"),\n",
    "    count(\"rating\").alias(\"total_reviews\")\n",
    ")\n",
    "\n",
    "\n",
    "product_meta = merged_df.select(\"asin\", \"brand\", \"main_category\").dropDuplicates([\"asin\"])\n",
    "\n",
    "\n",
    "brand_indexer = StringIndexer(inputCol=\"brand\", outputCol=\"brand_id\")\n",
    "product_meta = brand_indexer.fit(product_meta).transform(product_meta)\n",
    "\n",
    "\n",
    "category_indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"category_id\")\n",
    "product_meta = category_indexer.fit(product_meta).transform(product_meta)\n",
    "\n",
    "\n",
    "product_features = product_stats.join(product_meta.select(\"asin\", \"brand_id\", \"category_id\"), on=\"asin\", how=\"left\")\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"mean_rating\", \"total_reviews\", \"brand_id\", \"category_id\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "final_df = assembler.transform(product_features)\n",
    "\n",
    "final_df.select(\"asin\", \"mean_rating\", \"total_reviews\", \"brand_id\", \"category_id\", \"features\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133590e7-0bfb-4bdc-b88c-a47cf8f17b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(featuresCol=\"features\", k=5, seed=1)\n",
    "model = kmeans.fit(final_df)\n",
    "\n",
    "clustered = model.transform(final_df)\n",
    "clustered.select(\"asin\", \"prediction\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
